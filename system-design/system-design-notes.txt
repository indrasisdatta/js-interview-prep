System design tutorial: https://www.geeksforgeeks.org/system-design-tutorial/

Functional requirements (What the system should do to meet user needs - user authentication, data processing, user actions)
Non-functional requirements (How the system should perform - scalability, security, response time, reliability)

Components of System design:
 - Load balancer (ELB)
 - Caching (Redis, Memcache)
 - CDN (Cloudfront)
 - API Gateway (AWS API gateway)
 - Key value store (AWS DynamoDB)
 - Blob (Object) storage and database (AWS S3)
 - Rate limiter (AWS API gateway throttling)
 - Monitoring system (CloudWatch)
 - Distributed system messaging queue (SQS)
 - Distributed unique id generator (DynamoDB with UUID generation)
 - Distributed search/Elastic search - AWS Opensearch
 - Distributed logging service (CouldTrail, CloudWatch logs)
 - Distributed task scheduler (SNS)

Horizontal scaling/scale-out (add more servers to handle increased workload)
Vertical scaling/scale up (adding more CPU cores, memory or storage capacity to handle increased workload)

Load balancer - distribute the incoming traffic among servers to provide high availability, efficient server utilization and high performance.

Latency - time taken for a single task to complete (Request time + Response time) 
Throughput - No. of tasks completed in a given time period (High throughput usually means low latency)

Improve latency:
 - Deploy services closed to users (using CDN)
 - Load balancer and horizontal scaling
 - Optimize DB queries and index DB tables
 - Use caching Redis/Memcache
 - Async processing (handle non-critical tasks in the background eg. email notification in Amazon SQS)
 - DB sharding

Improve throughput: All above works, in addition to these: 
- Batch processing (Eg. instead of updating 100 transactions, 1 single query is fired instead of 100)
- Replication (use DB replica for read-heavy operations)

Database Sharding (eg. 4M rows -> 4 shards with 1M rows each)
- horizontal scaling of DB where data is split across multiple DB instances or shards 
Types of sharding:
 - Key based sharding (serverIndex = hashValue % numOfServers)
 - Range based sharding (customer name A-P in shard 1 and the rest in shard 2)
 - Vertical sharding (split multiple columns in single table to multiple tables)
    Eg. users (id, email, name, created_at) -> users (id, email, name) user_shard2 (user_id, created_at)
 - Directory based sharding (maintain lookup table for each shard)

CQRS Pattern (Command Query Responsibility Segregation)

CAP Theorem (Consistency, Availability, Partition tolerance)
 For applications where Consistency is crucial (e.g., banking, finance), a CP system is more appropriate. Availability might be sacrificed temporarily to ensure data accuracy. 
 For applications where Availability is more critical than strict data accuracy (e.g., social media feeds, online shopping), an AP system is usually chosen, allowing temporary inconsistencies that can later be corrected.

======================================================================

RADIO Concept

1) Requirements (functional and non-functional)
2) Architecture/HLD
3) Data model 
4) Interface definition (API)
5) Optimization

https://www.greatfrontend.com/system-design/framework

API Rate limiting strategies:
1. Token Bucket - allows for burst traffic by saving tokens 
   Eg. video streaming, large uploads
   Scenario: Ecommerce app launches a sale. Normally it receives 100 req/sec but during sales, it receives 1000/sec.
   Allow a short burst of up to 500 req/sec (using saved tokens).
   Once the burst capacity is exhausted, new req are queued or rate-limited.
2. Leaky Bucket - rate limiting for APIs where requests are served at a steady, fixed rate regarless of traffic spikes (Excess requests are dropped).
   Scenario. set up API to handle 100 req per sec.
   If 150 requests are made, the remaining 50 are dropped.

System design blog: https://www.eraser.io/decision-node

====================================================================

PROBLEM STATEMENT 1: How to handle sudden high traffic? Eg. Flipkart Sale start at 10am

ASG takes time to horizontally scale and spin up new instances, do health checks and get it ready (1-2 mins).
Traffic during these 1-2 mins are not handled and also increases the bill.

Better Solution: To build a highly scalable system, offload non-critical async tasks to Quueue

Critical tasks - place order (handle synchronously)
Non-critical tasks - send email (handle asyncronously)

Message Queue (Amazon SQS, Kafka) <- Consumer 
(Consumer pulls messsages. Set up rate limiter and concurrency control)

Scenario: User purchases a course and gets email notification on successful payment.
=> Problems
    1. Slow response time 
    2. Server may crash in case of large no. of concurrent requests 
    3. Email service may get blocked eg. 5,000 req received at once 

   Solution: Create separate Node app for queue (SQS/BullMQ/Kafka).

   BullMQ -> Producer, Consumer (Worker)

   Main app - producer code to save data in Queue 
   Queue app - consumer to read data from Queue and send emails 
   (Add limiter eg. max 50 emails per sec)

   Save data in Redis hosted in Aiven.

=========================================================================================================================

PROBLEM STATEMENT 2: 
2a: In an image sharing platform, implement a search feature where we can search by name, username and it returns a page with all images posted by the user
User Service -> User DB (contains millions of records)

Solution: Have a dedicated Search Service -> Search DB 
Event driven architecture - publish data from User service to a message broker. Search service subscribes to it. This keeps user data in sync.

2b: In newsfeed, show posts of all users which are followed by current logged in user.
Solution:  User A followes User B and User C.
user_id  |  timeline - sorted list of posts
---------------------------------------------
user_a   |  userb_post1, userc_post1, userb_post2, userc_post2

=> Posts service -> produce event (img_url, user_id, timestamp) when User B, C posts an image
=> Timeline service -> consume the event asynchronously (new_post -> newly created post)
   Subscribed data (img_url, user_id, timestamp)
   Send request to UserService to get followers of current logged in user 
   user_a -> user_b, userc (follower ids)
   
   user_b  [new_post, post1, post2 ... post5]
   user_c  [new_post, post3, post10,...]
   user_f [post7, post 8...]  // not updated as this user is not a follower

CQRS Pattern (Command Query Responsibility Segregation)
 - Command: user registration/updatest to user service
 - Query: search operations go to Search Service 



 











