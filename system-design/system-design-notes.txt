RADIO Concept

1) Requirements (functional and non-functional)
2) Architecture/HLD
3) Data model 
4) Interface definition (API)
5) Optimization

https://www.greatfrontend.com/system-design/framework


API Rate limiting strategies:
1. Token Bucket - allows for burst traffic by saving tokens 
   Eg. video streaming, large uploads
   Scenario: Ecommerce app launches a sale. Normally it receives 100 req/sec but during sales, it receives 1000/sec.
   Allow a short burst of up to 500 req/sec (using saved tokens).
   Once the burst capacity is exhausted, new req are queued or rate-limited.
2. Leaky Bucket - rate limiting for APIs where requests are served at a steady, fixed rate regarless of traffic spikes (Excess requests are dropped).
   Scenario. set up API to handle 100 req per sec.
   If 150 requests are made, the remaining 50 are dropped.

System design blog: https://www.eraser.io/decision-node

====================================================================

How to handle sudden high traffic? Eg. Flipkart Sale start at 10am

ASG takes time to horizontally scale and spin up new instances, do health checks and get it ready (1-2 mins).
Traffic during these 1-2 mins are not handled and also increases the bill.

Better Solution: To build a highly scalable system, offload non-critical async tasks to Quueue

Critical tasks - place order (handle synchronously)
Non-critical tasks - send email (handle asyncronously)

Message Queue (Amazon SQS, Kafka) <- Consumer 
(Consumer pulls messsages. Set up rate limiter and concurrency control)

Scenario: User purchases a course and gets email notification on successful payment.
=> Problems
    1. Slow response time 
    2. Server may crash in case of large no. of concurrent requests 
    3. Email service may get blocked eg. 5,000 req received at once 

   Solution: Create separate Node app for queue (SQS/BullMQ/Kafka).

   BullMQ -> Producer, Consumer (Worker)

   Main app - producer code to save data in Queue 
   Queue app - consumer to read data from Queue and send emails 
   (Add limiter eg. max 50 emails per sec)

   Save data in Redis hosted in Aiven.


Throughput - read/write operations per sec 
DB Throughput is usually low, so scalability is necessary 

For real time updates, we can't insert data in DB every sec. It affects throughput and causes lag.

Kafka has high throughput but can't store data for long.

1 consumer can consume multiple partitions. 
1 partition can be consumed by only 1 consumer, not possible (at Group level)

Self balancing - done at consumer group level 

Queue - 1 producer, 1 consumer 
Pub/Sub - 1 producer, multiple consumers 

Kafka can act both as a queue as well as pub/sub.
 - Queue: no. of partitions = no. of consumers (each apartition is assigned to each consumer)
 - Pub/Sub: multiple consumer groups














