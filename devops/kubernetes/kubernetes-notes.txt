Learning Resources:
    YouTube: https://www.youtube.com/watch?v=X48VuDVv0do
    Udemy course: https://cognizant.udemy.com/course/learn-kubernetes/learn/lecture/9703196#overview
__________________________________________________________________

Kubernetes - container orchestration system for managing containerized workloads and services (allows communication among different containers eg. microservices)

Cluster - set of 1 master and multiple worker nodes 

Need for container orchestration tool - In Microservices, with increased usage of containers, there's a demand for a proper way to manage hundreds of containers 
- High availability
- Scalability
- Disaster recovery 
____________________________________________________________

KUBERNETES COMPONENTS:

1. Pod: Smallest unit of K8s, abstraction over container (layer on top of container). Usually 1 application per pod. 
Each pod gets its own IP address.
New IP address on re-creation.

2. Service: Permanent IP address. Life cycle of pod and service are not connected (even if pod dies, service isn't affected). Also acts as load balancer. Define blueprint for pods to create pod replica.

3. Ingress - request comes to ingress first, then forwarded to external service. Ingress has url like https://my-ap.com and ext service has url like 127.0.0.1:80

4. ConfigMap: external configuration of your application (Eg. DB credentials)
Insted of building app every time config is changed, fetch from ConfigMap.
Secrets: For DB password 

K8s cluster explicitly doesn't manage data persistence. If DB container or pod is restarted, data will be gone. 
Volumes - attaches physical storage or hard drive to the pod. Storage can be in local (same server node) or remote storage (cloud).

Deployment: blueprint for my-app pods. Abstraction of pods. Not used for DB.

StatefulSet: for stateful apps eg. DB. 
DB are often hosted outside K8s cluster.
____________________________________________________________

WORKER MACHINE IN K8S CLUSTER 

Communication across different nodes is done using services
Each nodes has multiple pods
3 processes must be installed on every node 
    1. Container runtime eg. Docker
    2. Kubelet (interacts with both container and node. Starts the pod with a container inside)
    3. Kube proxy (forwarding request from services to pods - intelligent forwarding logic is present as it forwards to replicate on the same node if present, thus saving overhead)
 
Worker node do the actual work.
Master node helps to manage 

MASTER PROCESS 
4 processes must be in Master node:
    1. API server - interact with API server using some client. It's like a cluster gateway and acts as a gatekeeper for authentication. (Load balancer)
    2. Scheduler - checks worker node resources to decide where to put the new pod.
    Kubelet gets the request.
    3. Controller manager - detects cluster state changes eg. crashing of pods. When pods die, it makes request to scheduler to restart the pods. 
    4. etcd - Key value store to save cluster state info (eg. is the cluster state healthy, what resources are available, did the cluster state change) 
    application data is not stored in etcd.
    Distributed storage across all master nodes

2 Master - need less resources
3 Worker nodes - more resources 

Add new master/node server:
1. Get new bare server
2. Install all master/worker node processes 
3. Add it to the cluster.

Minikube - master and worker processes work on 1 node (test/local setup). Docker pre-installed. Creates virtual box on your machine and node runs in that virtual box.
kubectl - CLI tool to interact with Kubenetes setup.

minikube is used to start and delete cluster. kubectl is used for all other commands.

We can't create pod directly, need to create deployment as it's an abstraction on pod. 

CLI COMMANDS:
    // Get latest nginx docker image
    kubectl create deployment nginx-depl --image=nginx 
    kubectl get deployment 
    kubectl get pod 
    kubectl get replicaset 
    // edit config file generated at the time of creatng the deployment
    kubectl edit deployment nginx-depl 
    // open interactive terminal to debug the pod
    kubectl exec -it <pod-name> -- bin/bash
    // Run create/update command based on yaml file contents
    kubectl apply -f config.yaml
    kubectl describe service service-name
    # Yaml output written to nginx-depl.yaml
    kubectl get deployment <deployment-name> -o yaml > nginx-depl.yaml

Deployment (manages ->) ReplicaSet (manages ->) Pod (abstraction of ->) Container 
Everything below deployment is managed by Kubernetes 
If deployment is edited, everything below is re-created automatically.

Config file:
 - metadata
 - specification 
 - status (added automatically by K8s, keeps changing)

etcd holds the current status of any K8s components 

metadata:
    .....
spec: 
    # template has its own metadata & specs sections
    # applies to pods 
    template:
        metadata: 
            ....
        specs: 
            containers:
            ....

Internal service type is ClusterIP
External service type is LoadBalancer (LB assigns internal + external IP)

# Assign external IP to service
minikube service <service-name> 

Namespace - use cases:
1. Structure your components
2. Avoid conflicts among teams - many teams, same application (same namespace can override existing one)
3. Resource sharing in different env or Blue/Green deployment 
4. Access and resource limits on namespaces
   (Limit CPU, RAM, storage in namespace)

- Each NS should have its own ConfigMap. 
- Some components live globally in the cluster, NS not allowed (Eg. volume, node)

Install kubens - switch active namespace. No need to mention --namespace in CLI every time

# Install ingress controller in minikube
# automatically starts K8s nginx implementation of ingress controller 
minikube addons enable ingress

kubectl get pod -n kube-system

Access K8s dashboard from some domain name 
kubectl get ns 
kubectl get all -n kubernetes-dashboard 

Configuring TLS certificate 
// Secret component 
metadata: 
    name: myaoo-secret-tls 
    namespace: default 
data: 
    tls.crt: base64 encoded crt 
    tls.key: base64 encoded key 

Secret component must be in the same namespace as the ingress component 

HELM CHARTS 
- Bundle of Yaml files 
- Create your own Helm charts with Helm and push to helm repo 
- Dowload and use existing ones 

https://youtu.be/X48VuDVv0do?t=8882

Helm - templating engine: instead of having multiple 1 yaml file for each microservice, use 1 yaml file and replace values dynamically.
During CI/CD build, replace the values on the fly.
// values.yaml 
name: my-app
container: 
    name: my-app-container
    image: my-app-image
    port: 9001 

helm install <chartname> - template files will be filled with values from values.yaml

Persistent volumes are not namespaced

K8s admin (Devops) - sets up and maintains the cluster, they handle configuration 
K8s user (Developers) - configure yaml file to use persistent volume components 

Application has to claim the Persistent volume - PVC (Persistent volume claim)

Storage class - provisions persistent volumes dynamically, when PVC claims it.

Deployment - stateless apps (Eg. Node.js app)
StatefulSet - stateful apps (Eg. MongoDB)

Pod identity 
 - Deployment: random hash 
 - StatefulSet: fixed ordered numbers (Eg. mysql-0, mysql-1, mysql-2)
 Next pod is created if previous one is up and running 
 Deletetion of pod is done in reverse order (2, 1, 0)

 - Predictable pod name (mysql-0)
 - fixed individual DNS name (mysql-0.svc2)
 When pod restarts, IP changes but name and endpoint stays the same.

Stateful apps are not perfect for containerized apps 

____________________________________________________________

K8S SERVICES 

Service features:
 - Stable IP address (Pods are ephemeral - destroyed frequently so new IP assigned)
 - Load balancing 

ClusterIP Services (default) 
How does service know which pod to forward the request to?
How does service know which port to forward to? If pod has multiple ports.
=> ports: 
    - protocol: TCP
      port: 3200
      targetPort: 3000 // forwarded to this port 

Headless Service - return pod IP  
clusterIP: none 

NodePort Service - not secure, not used for external 

LoadBalancer Service - becomes accessible externally through cloud providers 

LoadBalancer -> extension of NodePort -> extension of ClusterIP 

Udemy course: https://cognizant.udemy.com/course/learn-kubernetes/learn/lecture/10957998

Course answers: https://github.com/mmumshad/kubernetes-training-answers







